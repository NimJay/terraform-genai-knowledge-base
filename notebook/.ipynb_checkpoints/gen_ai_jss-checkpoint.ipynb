{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e",
    "tags": []
   },
   "source": [
    "# Generative AI Enterprise Knowledge Base Chatbot\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/terraform-genai-extractive-qa/blob/main/terraform/webhooks/notebook/gen_ai_jss.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/terraform-genai-extractive-qa/main/terraform/webhooks/notebook/gen_ai_jss.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/terraform-genai-extractive-qa/main/terraform/webhooks/notebook/gen_ai_jss.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>                                                                                               \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24743cf4a1e1"
   },
   "source": [
    "**_NOTE_**: This notebook has been tested in the following environment:\n",
    "\n",
    "* Python version = 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook is a companion to the [Generative AI Enterprise Knowledge Base Jump Start Solution](https://cloud.google.com/blog/products/application-modernization/introducing-google-cloud-jump-start-solutions). With this notebook, you can use the Jumpstart Solution to extract questions & answers from a PDF document. In the notebook, you will programmatically upload a PDF file to a Cloud Storage bucket, send the PDF off for optical character recognition, extract questions and answers from the recognized text, and then tune a Vertex PaLM model with the extracted Q&As. \n",
    "\n",
    "+ Learn more about [using text chat LLM with Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview).\n",
    "+ Learn more about [querying collections in Firestore](https://cloud.google.com/firestore/docs/query-data/get-data).\n",
    "+ Learn more about [creating EventArc triggers for Cloud Functions](https://cloud.google.com/functions/docs/calling/eventarc).\n",
    "+ Learn more about [storing data in Cloud Storage](https://cloud.google.com/storage/docs/uploading-objects).\n",
    "+ Learn more about [transcribing PDFs with Cloud Vision OCR](https://cloud.google.com/vision/docs/pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you learn how to create a Cloud Function process that transcribes characters from a PDF, stores the complete PDF text in a Storage bucket, extracts Q&As from the PDF, and then upserts the document data (summary, complete text, URI) into a Firestore collection.\n",
    "\n",
    "This tutorial uses the following Google Cloud services and resources:\n",
    "\n",
    "- Vertex AI Generative AI\n",
    "- Cloud Firestore\n",
    "- Cloud Vision OCR\n",
    "- Cloud EventArc triggers\n",
    "- Cloud Functions\n",
    "- Cloud Storage\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Trigger an EventArc event by uploading a PDF to a Cloud Storage bucket\n",
    "- Query the Firestore collection to see the results of the extraction process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08d289fa873f"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "This notebook uses a **TODO: Insert reference to dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aed92deeb4a0"
   },
   "source": [
    "### Costs \n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "* Firestore\n",
    "* Vision\n",
    "* Cloud Functions\n",
    "* EventArc\n",
    "* Cloud Storage\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
    "and [BigQuery pricing](https://cloud.google.com/bigquery/pricing),\n",
    "and [Cloud Vision pricing](https://cloud.google.com/vision/pricing),\n",
    "and [Cloud Functions pricing](https://cloud.google.com/functions/pricing),\n",
    "and [Cloud EventArc pricing](https://cloud.google.com/eventarc/pricing),\n",
    "and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), \n",
    "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the following packages required to execute this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "google-cloud-aiplatform\n",
    "google-cloud-firestore\n",
    "google-cloud-logging\n",
    "google-cloud-storage\n",
    "google-cloud-vision\n",
    "pandas\n",
    "polling2\n",
    "tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /root/.local/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-firestore in /root/.local/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (2.12.0)\n",
      "Requirement already satisfied: google-cloud-logging in /root/.local/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (3.8.0)\n",
      "Requirement already satisfied: google-cloud-storage in /root/.local/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (2.12.0)\n",
      "Requirement already satisfied: google-cloud-vision in /root/.local/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (3.4.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (1.3.5)\n",
      "Requirement already satisfied: polling2 in /root/.local/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (0.5.0)\n",
      "Requirement already satisfied: tqdm in /root/.local/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (4.66.1)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (1.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (1.22.3)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (23.1)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (3.11.4)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (1.10.3)\n",
      "Requirement already satisfied: shapely<2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (1.8.5.post1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-firestore->-r requirements.txt (line 3)) (2.3.3)\n",
      "Requirement already satisfied: google-cloud-appengine-logging<2.0.0dev,>=0.1.0 in /root/.local/lib/python3.7/site-packages (from google-cloud-logging->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: google-cloud-audit-log<1.0.0dev,>=0.1.0 in /root/.local/lib/python3.7/site-packages (from google-cloud-logging->-r requirements.txt (line 4)) (0.2.5)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.7/site-packages (from google-cloud-logging->-r requirements.txt (line 4)) (0.12.6)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.23.3 in /root/.local/lib/python3.7/site-packages (from google-cloud-storage->-r requirements.txt (line 5)) (2.23.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /root/.local/lib/python3.7/site-packages (from google-cloud-storage->-r requirements.txt (line 5)) (2.6.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage->-r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage->-r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 7)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 7)) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 7)) (1.21.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (1.60.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (1.57.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage->-r requirements.txt (line 5)) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage->-r requirements.txt (line 5)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage->-r requirements.txt (line 5)) (4.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r requirements.txt (line 5)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r requirements.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r requirements.txt (line 5)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r requirements.txt (line 5)) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage->-r requirements.txt (line 5)) (0.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    USER = \"--user\"\n",
    "else:\n",
    "    USER = \"\"\n",
    "! pip3 install {USER} --upgrade -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58707a750154"
   },
   "source": [
    "### Colab only: Uncomment the following cell to restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f200f10a1da3"
   },
   "outputs": [],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "## Before you begin\n",
    "\n",
    "### Set up your Google Cloud project\n",
    "\n",
    "This notebook assumes that you have already deployed this solution using either the [Terraform script]() **TODO: fix target for link** or using the [Solutions console](https://console.cloud.google.com/products/solutions/catalog). During this deployment, several actions required to run this solution were performed on your behalf:\n",
    "\n",
    "1. The [Cloud Function](https://console.cloud.google.com/functions/list) was deployed.\n",
    "\n",
    "2. The [EventArc trigger](https://console.cloud.google.com/eventarc/triggers) was applied to the input Cloud Storage bucket.\n",
    "\n",
    "3. The following APIs were enabled for you: \n",
    "\n",
    "   - [Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
    "   - [BigQuery API](https://console.cloud.google.com/flows/enableapi?apiid=bigquery.googleapis.com)\n",
    "   - [Cloud Vision API](https://console.cloud.google.com/flows/enableapi?apiid=vision.googleapis.com)\n",
    "\n",
    "\n",
    "<div style=\"background-color:rgb(150,200,255); padding:2px;\"><strong>Note:</strong> It is recommended to run this notebook from <a href=\"https://console.cloud.google.com/vertex-ai/workbench/\">Vertex AI Workbench</a>. If you are running this notebook locally instead, you need to install the <a href=\"https://cloud.google.com/sdk\" target=\"_blank\">Cloud SDK</a>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "### Authenticate your Google Cloud account\n",
    "\n",
    "Depending on your Jupyter environment, you may have to manually authenticate. Follow one of the relevant instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ccc9e52986"
   },
   "source": [
    "**1. Vertex AI Workbench**\n",
    "* Do nothing as you are already authenticated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de775a3773ba"
   },
   "source": [
    "**2. Local JupyterLab instance, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "254614fa0c46"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef21552ccea8"
   },
   "source": [
    "**3. Colab, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "603adbbf0532"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6b2ccc891ed"
   },
   "source": [
    "**4. Service account or other**\n",
    "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas\n",
    "import polling2\n",
    "import re\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Tuple\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import firestore\n",
    "from google.cloud import logging\n",
    "from google.cloud import storage\n",
    "from google.cloud import vision\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download test data\n",
    "\n",
    "This Jump Start Solution uses data from [arXiv.org](https://arxiv.org/) to demonstrate the summarization capabilities of Vertex AI. arXiv, through [Kaggle.com](https://www.kaggle.com/datasets/Cornell-University/arxiv) has made many scholarly papers available, free of charge, from a Google Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the comparative linguistics papers from Cloud Storage\n",
    "! gsutil ls gs://arxiv-dataset/arxiv/cmp-lg/pdf/9404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '9404002v1'\n",
    "file_uri = f'gs://arxiv-dataset/arxiv/cmp-lg/pdf/9404/{filename}.pdf'\n",
    "\n",
    "# Create a local folder and download some test PDFs\n",
    "if not os.path.exists('pdfs'):\n",
    "    os.mkdir('pdfs')\n",
    "\n",
    "! gsutil cp -r $file_uri pdfs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload test data to Storage bucket\n",
    "\n",
    "The Terraform scripts for this JSS applies an EventArc trigger to a Cloud Storage bucket. When a PDF is uploaded to the storage bucket, the EventArc trigger fires, starting the summarization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_BUCKET = f'{PROJECT_ID}_uploads'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the next cell uploads a local PDF file (downloaded in the previous section) to the target Cloud Storage bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_complete_text = f'{filename}_summary.txt'\n",
    "pdf = f'pdfs/{filename}.pdf'\n",
    "logger_name = 'summarization-by-llm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(INPUT_BUCKET)\n",
    "blob = bucket.blob(pdf)\n",
    "blob.upload_from_filename(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This upload process kicks off the summarization process. You can view the progress of the summarization process in the [Cloud Console](https://console.cloud.google.com/functions/details/us-central1/jss16-1).\n",
    "\n",
    "**TODO: Ensure that Cloud Console links go to correct console locations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: View summarization process in Cloud Logging\n",
    "\n",
    "You can view the results of the summarization Cloud Function as it writes updates to Cloud Logging. Each run of the summarization pipeline is associated with a `cloud_event_id`. By filtering for this ID, you can track the summarization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@polling2.poll_decorator(check_success=lambda x: x != '', step=0.5, timeout=90)\n",
    "def get_cloud_event_id(pdf_filename, bar):\n",
    "    logging_client = logging.Client(project=PROJECT_ID)\n",
    "    logger = logging_client.logger(logger_name)\n",
    "    \n",
    "    pattern = 'cloud_event_id\\((.*)\\):'\n",
    "    cloud_id = ''\n",
    "    for entry in logger.list_entries(filter_=pdf_filename, max_results=100):\n",
    "        entry_text = entry.payload\n",
    "        res = re.search(pattern, entry_text)\n",
    "        if res != None:\n",
    "            cloud_id = res.group(1)\n",
    "            print(cloud_id)\n",
    "            bar.update(100)\n",
    "    \n",
    "        if cloud_id != '':\n",
    "            return cloud_id\n",
    "    return cloud_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=100) as bar:\n",
    "    cloud_event_id = get_cloud_event_id(filename, bar)\n",
    "    bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the `cloud_event_id`, we can filter on just this cloud event and get updates for just this event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'cloud_event_id: {cloud_event_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@polling2.poll_decorator(step=10, timeout=70)\n",
    "def get_cloud_event_logs(cloud_event_id):\n",
    "    print(\"polling\")\n",
    "    logging_client = logging.Client(project=PROJECT_ID)\n",
    "    logger = logging_client.logger(logger_name)\n",
    "    \n",
    "    entries = []\n",
    "    for entry in logger.list_entries(filter_=cloud_event_id, max_results=100):\n",
    "        entry_text = entry.payload\n",
    "        entries.append(entry_text)\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "bar = tqdm(total=6)\n",
    "\n",
    "for _ in range(6):\n",
    "    tmp_entries = get_cloud_event_logs(cloud_event_id)\n",
    "    for e in tmp_entries:\n",
    "        if e not in entries:\n",
    "            bar.update(1)\n",
    "            entries.append(e)\n",
    "            print(e)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the BigQuery table to see the summary\n",
    "\n",
    "Once the summarization flow has completed, the summary of the PDF document should be available for you to read. To get the summary of the PDF document, you can query the BigQuery table that contains the summary.\n",
    "\n",
    "If you do not get a result the first time you run the query, then the summarization pipeline might still be running. You might need to wait a minute to allow the pipeline to finish and to try the query again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigquery_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "table_name = f\"{PROJECT_ID}.summary_dataset.summary_table\"\n",
    "\n",
    "# Compose the SQL query to select the summary for the PDF document\n",
    "sql_query = f\"SELECT summary FROM `{table_name}` WHERE filename LIKE '%{file_complete_text}%'\"\n",
    "\n",
    "job = bigquery_client.query(sql_query)\n",
    "rows = job.result()\n",
    "row_list = list(rows)\n",
    "\n",
    "if len(row_list) != 0:\n",
    "    summary = row_list[0]\n",
    "\n",
    "print(summary['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Run pipeline components individually\n",
    "\n",
    "The summarization pipeline is composed of multiple independent components. There is a component that performs optical character recognition on the PDF, another that stores data in a Storage bucket, another that performs summarization with a LLM, and yet another that stores new rows into the BigQuery table.\n",
    "\n",
    "In this section, you can run each component individually to understand how they work together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(erschmid): Delete this cell when ready to push to remote\n",
    "PROJECT_ID = 'jss-22p1-test'\n",
    "REGION = 'us-central1'\n",
    "COLLECTION = 'extractive-qa-nb-test'\n",
    "BUCKET = 'jss-22p1-test'\n",
    "PREFIX = 'extractive-qa-nb-test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform OCR with Cloud Vision\n",
    "\n",
    "The first component in the pipeline performs optical character recognition (OCR) using Cloud Vision. Run the following cells to run optical character recognition on the PDF file you downloaded previously.\n",
    "\n",
    "Note that OCR can take a while to complete. You might need to wait for a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_extract(\n",
    "    bucket: str,\n",
    "    name: str,\n",
    "    output_bucket: str,\n",
    "    project_id: str,\n",
    "    timeout: int = 420,\n",
    ") -> str:\n",
    "    \"\"\"Perform OCR with PDF/TIFF as source files on GCS.\n",
    "\n",
    "    Original sample is here:\n",
    "    https://github.com/GoogleCloudPlatform/python-docs-samples/blob/main/vision/snippets/detect/detect.py#L806\n",
    "\n",
    "    Note: This function can cause the IOPub data rate to be exceeded on a\n",
    "    Jupyter server. This rate can be changed by setting the variable\n",
    "    `--ServerApp.iopub_data_rate_limit\n",
    "\n",
    "    Args:\n",
    "        bucket (str): GCS URI of the bucket containing the PDF/TIFF files.\n",
    "        name (str): name of the PDF/TIFF file.\n",
    "        output_bucket: bucket to store output in\n",
    "        timeout (int): Timeout in seconds for the request.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        str: the complete text\n",
    "    \"\"\"\n",
    "\n",
    "    gcs_source_uri = f\"gs://{bucket}/{name}\"\n",
    "    prefix = \"ocr\"\n",
    "    gcs_destination_uri = f\"gs://{output_bucket}/{prefix}/\"\n",
    "    mime_type = \"application/pdf\"\n",
    "    batch_size = 2\n",
    "\n",
    "    # Perform Vision OCR\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    feature = vision.Feature(type_=vision.Feature.Type.DOCUMENT_TEXT_DETECTION)\n",
    "\n",
    "    gcs_source = vision.GcsSource(uri=gcs_source_uri)\n",
    "    input_config = vision.InputConfig(gcs_source=gcs_source, mime_type=mime_type)\n",
    "\n",
    "    gcs_destination = vision.GcsDestination(uri=gcs_destination_uri)\n",
    "    output_config = vision.OutputConfig(\n",
    "        gcs_destination=gcs_destination, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    async_request = vision.AsyncAnnotateFileRequest(\n",
    "        features=[feature], input_config=input_config, output_config=output_config\n",
    "    )\n",
    "\n",
    "    operation = client.async_batch_annotate_files(requests=[async_request])\n",
    "\n",
    "    print(\"OCR: waiting for the operation to finish.\")\n",
    "    operation.result(timeout=timeout)\n",
    "\n",
    "    # Once the request has completed and the output has been\n",
    "    # written to GCS, we can list all the output files.\n",
    "    print(\"OCR: complete\")\n",
    "    return get_ocr_output_from_bucket(gcs_destination_uri, output_bucket, project_id)\n",
    "\n",
    "\n",
    "def get_ocr_output_from_bucket(gcs_destination_uri: str,\n",
    "                               bucket_name: str,\n",
    "                               project_id: str) -> str:\n",
    "    \"\"\"Iterates over blobs in output bucket to get full OCR result.\n",
    "\n",
    "    Arguments:\n",
    "        gcs_destination_uri: the URI where the OCR output was saved.\n",
    "        bucket_name: the name of the bucket where the output was saved.\n",
    "\n",
    "    Returns:\n",
    "        The full text of the document\n",
    "    \"\"\"\n",
    "    print(\"Storage: fetching complete text\")\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "\n",
    "    match = re.match(r\"gs://([^/]+)/(.+)\", gcs_destination_uri)\n",
    "    prefix = match.group(2)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    # List objects with the given prefix, filtering out folders.\n",
    "    blob_list = [\n",
    "        blob\n",
    "        for blob in list(bucket.list_blobs(prefix=prefix))\n",
    "        if not blob.name.endswith(\"/\")\n",
    "    ]\n",
    "\n",
    "    # Concatenate all text from the blobs\n",
    "    complete_text = \"\"\n",
    "    for output in blob_list:\n",
    "        json_string = output.download_as_bytes().decode(\"utf-8\")\n",
    "        response = json.loads(json_string)\n",
    "\n",
    "        # The actual response for the first page of the input file.\n",
    "        page_response = response[\"responses\"][0]\n",
    "        annotation = page_response[\"fullTextAnnotation\"]\n",
    "\n",
    "        complete_text = complete_text + annotation[\"text\"]\n",
    "\n",
    "    return complete_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR: waiting for the operation to finish.\n",
      "OCR: complete\n",
      "Storage: fetching complete text\n",
      "Aristotle on Happiness\n",
      "A Little Background\n",
      "Aristotle is one of the\n",
      "greatest thinkers in the\n",
      "history of western science\n",
      "and philosophy, making\n",
      "contributions to logic,\n",
      "metaphysics, mathematics,\n",
      "physics, biology, botany,\n",
      "ethics, politics, agriculture,\n",
      "medicine, dance and theatre.\n",
      "He was a student of Plato\n",
      "who in turn studied under\n",
      "Socrates. Although we do not\n",
      "actually possess any of\n",
      "Aristotle's own writings\n",
      "intended for publication, we\n",
      "have volumes of the lecture\n",
      "notes he delivered for his\n",
      "students; through these\n",
      "Aristotle was to exercise his profound influence through the ages. Indeed, the medieval outlook\n",
      "is sometimes considered to be the \"Aristotelian worldview\" and St. Thomas Aquinas simply\n",
      "refers to Aristotle as \"The Philosopher\" as though there were no other.\n",
      "Aristotle was the first to classify areas of human knowledge into distinct disciplines such as\n",
      "mathematics, biology, and ethics. Some of these classifications are still used today, such as the\n",
      "species-genus system taught in bio\n"
     ]
    }
   ],
   "source": [
    "pdf_name = f\"{PREFIX}/aristotle-on-happiness.pdf\"\n",
    "output_bucket = f\"{PROJECT_ID}_output\"\n",
    "\n",
    "complete_text = document_extract(bucket=BUCKET,\n",
    "                                 name=pdf_name,\n",
    "                                 output_bucket=output_bucket,\n",
    "                                 project_id=PROJECT_ID)\n",
    "\n",
    "# Entire text is long; print just first 1000 characters\n",
    "print(complete_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract questions & answers with the Vertex AI PaLM API\n",
    "\n",
    "Next, you can send the complete text of the PDF to extract questions from. Vertex AI allows you to use many different types of LLM models. In this case, you use a LLM model designed for text summarization, `text-bison@001`. You send a prediction request to Vertex AI, providing the name of the LLM you want to use. The Vertex AI service then sends the model's response back to you. In the following cells, the Python SDK for Vertex AI provides all of the helper methods and classes you need to perform this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_questions(\n",
    "        *,\n",
    "        project_id: str,\n",
    "        model_name: str,\n",
    "        text: str,\n",
    "        temperature: float = 0.2,\n",
    "        max_decode_steps: int = 1024,\n",
    "        top_p: float = 0.8,\n",
    "        top_k: int = 40,\n",
    "        location: str = \"us-central1\",\n",
    ") -> str:\n",
    "    \"\"\"Extract questions & answers using a large language model (LLM)\n",
    "\n",
    "    Args:\n",
    "        project_id (str): the Google Cloud project ID\n",
    "        model_name (str): the name of the LLM model to use\n",
    "        temperature (float): controls the randomness of predictions\n",
    "        max_decode_steps (int): the number of tokens to generate\n",
    "        top_p (float): cumulative probability of parameter highest vocabulary tokens\n",
    "        top_k (int): number of highest probability vocabulary tokens to keep for top-k-filtering\n",
    "        text (str): the text to summarize\n",
    "        location (str): the Google Cloud region to run in\n",
    "\n",
    "    Returns:\n",
    "        The summarization of the content\n",
    "    \"\"\"\n",
    "    vertexai.init(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "    )\n",
    "\n",
    "    model = TextGenerationModel.from_pretrained(model_name)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Extract at least 10 questions with answers based on the following article: {text}\n",
    "    \n",
    "    Questions: Answers:\n",
    "    \"\"\"\n",
    "    response = model.predict(\n",
    "        prompt,\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=max_decode_steps,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "    question_list = response.text.splitlines()\n",
    "\n",
    "    return question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"text-bison@001\"\n",
    "temperature = 0.2\n",
    "max_decode_steps = 1024\n",
    "top_p = 0.8\n",
    "top_k = 40\n",
    "\n",
    "qas = extract_questions(\n",
    "    project_id=PROJECT_ID,\n",
    "    model_name=model_name,\n",
    "    text=complete_text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 1. What did Aristotle study?\n",
      "Answer: Aristotle studied logic, metaphysics, mathematics, physics, biology, botany, ethics, politics, agriculture, medicine, dance and theatre.\n",
      "Question: 2. Who was Aristotle's teacher?\n",
      "Answer: Aristotle's teacher was Plato.\n",
      "Question: 3. What did Aristotle write?\n",
      "Answer: Aristotle wrote volumes of lecture notes that he delivered for his students.\n",
      "Question: 4. What did Aristotle classify?\n",
      "Answer: Aristotle classified areas of human knowledge into distinct disciplines such as mathematics, biology, and ethics.\n",
      "Question: 5. What did Aristotle devise?\n",
      "Answer: Aristotle devised a formal system for reasoning.\n",
      "Question: 6. What is an example of a syllogism?\n",
      "Answer: All men are mortal; Socrates is a man; therefore, Socrates is mortal.\n",
      "Question: 7. What area of thought did Aristotle's brand of logic dominate?\n",
      "Answer: Aristotle's brand of logic dominated the area of thought until the rise of modern symbolic logic.\n",
      "Question: 8. What is the medieval outlook sometimes considered to be?\n",
      "Answer: The medieval outlook is sometimes considered to be the \"Aristotelian worldview.\"\n",
      "Question: 9. What does St. Thomas Aquinas refer to Aristotle as?\n",
      "Answer: St. Thomas Aquinas refers to Aristotle as \"The Philosopher\" as though there were no other.\n",
      "Question: 10. What is the species-genus system?\n",
      "Answer: The species-genus system is a classification system that Aristotle devised.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "qa_pairs = []\n",
    "while True:\n",
    "    question = qas[count]\n",
    "    count += 1\n",
    "    answer = qas[count]\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    \n",
    "    qa_pairs.append((question, answer))\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count >= len(qas):\n",
    "        break\n",
    "    \n",
    "    if qas[count] == \"\":\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store question & answer pairs in Firestore\n",
    "\n",
    "The following cells saves all of the question and answer pairs as as documents in Firestore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_qas_to_collection(\n",
    "    project_id: str,\n",
    "    collection_name: str,\n",
    "    question_answer_pairs: List[Tuple[str, str]],\n",
    "    input_file_gcs_uri: str,\n",
    "    time_created: datetime,\n",
    "):\n",
    "    \"\"\"Writes question and answer pairs to the specified Firestore collection.\n",
    "\n",
    "    Arguments:\n",
    "      project_id: the project that contains this database\n",
    "      collection_name: the collection to store the Q&A pairs in\n",
    "      question_answer_pairs: the Q&A pairs to add\n",
    "      input_file_gcs_uri: the Cloud Storage URI for the source PDF\n",
    "      time_created: the time that this PDF was uploaded\n",
    "    \"\"\"\n",
    "    db = firestore.Client(project=project_id)\n",
    "    bulkwriter = db.bulk_writer()\n",
    "\n",
    "    for qa in question_answer_pairs:\n",
    "\n",
    "        # Create a unique ID for each question\n",
    "        question_hash = hash(qa[0])\n",
    "\n",
    "        doc_ref = db.document(collection_name, str(question_hash))\n",
    "        doc_snap = doc_ref.get()\n",
    "\n",
    "        document_data = {\n",
    "            \"question\": qa[0],\n",
    "            \"answers\": [{\n",
    "                \"answer\": qa[1],\n",
    "                \"gcs_uri\": input_file_gcs_uri,\n",
    "                \"time_uploaded\": time_created,\n",
    "            }]\n",
    "        }\n",
    "\n",
    "        if doc_snap.exists:\n",
    "            bulkwriter.update(doc_ref, document_data)\n",
    "            continue\n",
    "\n",
    "        bulkwriter.create(doc_ref, document_data)\n",
    "\n",
    "    # Send all updates and close the BulkWriter\n",
    "    bulkwriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_qas_to_collection(\n",
    "    project_id=PROJECT_ID,\n",
    "    collection_name=COLLECTION,\n",
    "    question_answer_pairs=qa_pairs,\n",
    "    input_file_gcs_uri=f\"gs://{BUCKET}/{pdf_name}\",\n",
    "    time_created=datetime.now().isoformat()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune a customized LLM\n",
    "\n",
    "The following cells fine tune an LLM using the question & answer pairs stored in the Firestore collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qas_from_collection(\n",
    "    *,\n",
    "    project_id: str,\n",
    "    collection_name: str,\n",
    "    bucket_name: str,\n",
    ") -> str:\n",
    "    \"\"\"Gets all QA sets as a list of dict objects.\n",
    "\n",
    "    Arguments:\n",
    "      project_id: the project that contains this database\n",
    "      collection_name: the collection to get the Q&A pairs from\n",
    "\n",
    "    Returns:\n",
    "        Cloud Storage URI of a JSONL document with all QA pairs\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import os\n",
    "    from google.cloud import firestore\n",
    "    from google.cloud import storage\n",
    "\n",
    "    db = firestore.Client(project=project_id)\n",
    "    collection_ref = db.collection(collection_name)\n",
    "    docs_iter = collection_ref.stream()\n",
    "\n",
    "    all_qas = []\n",
    "\n",
    "    for doc in docs_iter:\n",
    "        qa = doc.to_dict()\n",
    "        all_qas.append(qa)\n",
    "\n",
    "    gcs_qa_dir = f\"gs://{bucket_name}/extractive-qa\"\n",
    "    gcs_qa_file = f\"{gcs_qa_dir}/qas.json\"\n",
    "    \n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(f\"extractive-qa/qas.json\")\n",
    "\n",
    "    blob.upload_from_string(json.dumps(all_qas))\n",
    "\n",
    "    return gcs_qa_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning(\n",
    "        *,\n",
    "        project_id: str,\n",
    "        location: str = \"us-central1\",\n",
    "        gcs_qa_file: str = \"\",\n",
    "        tuned_model_name: str = \"\",\n",
    ") -> \"_LanguageModelTuningJob\":\n",
    "    \"\"\"Tune a new model, based on Q&A data stored in a Firestore collection.\n",
    "\n",
    "    Args:\n",
    "        project_id: Google Cloud project ID, used to initialize Vertex AI\n",
    "        location: Google Cloud region, used to initialize Vertex AI\n",
    "        gcs_qa_file: Cloud Storage FUSE URI of a file containing questions & answers\n",
    "        tuned_model_name: name of a previously tuned model\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    \n",
    "    from google.cloud import storage\n",
    "    \n",
    "    import vertexai\n",
    "    from vertexai.preview.language_models import TextGenerationModel\n",
    "    \n",
    "    vertexai.init(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "    )\n",
    "\n",
    "    if tuned_model_name == \"\":\n",
    "        model = TextGenerationModel.from_pretrained(\"google/text-bison@001\")\n",
    "\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    uri_paths = gcs_qa_file.split(\"/\")\n",
    "    bucket = storage_client.bucket(uri_paths[2])\n",
    "    blob_path = \"/\".join(uri_paths[3:])\n",
    "    blob = bucket.blob(blob_path)\n",
    "    jsonl_as_str = blob.download_as_string()\n",
    "    \n",
    "    qas = json.loads(jsonl_as_str)\n",
    "    jsonl_dataset = [{\"input_text\": qa[\"question\"],\n",
    "                      \"output_text\": qa[\"answers\"][0][\"answer\"]} for qa in qas]\n",
    "    print(jsonl_dataset)\n",
    "    job = model.tune_model(\n",
    "        training_data=pd.DataFrame(data=jsonl_dataset),\n",
    "        # Optional:\n",
    "        train_steps=10,\n",
    "        tuning_job_location=\"europe-west4\",\n",
    "        tuned_model_location=location,\n",
    "    )\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_question': '3. What did Aristotle write?', 'output_text': 'Aristotle wrote volumes of lecture notes that he delivered for his students.'}, {'input_question': '6. What is an example of a syllogism?', 'output_text': 'All men are mortal; Socrates is a man; therefore, Socrates is mortal.'}, {'input_question': '10. What is the species-genus system?', 'output_text': 'The species-genus system is a classification system that Aristotle devised.'}, {'input_question': '5. What did Aristotle devise?', 'output_text': 'Aristotle devised a formal system for reasoning.'}, {'input_question': \"7. What area of thought did Aristotle's brand of logic dominate?\", 'output_text': \"Aristotle's brand of logic dominated the area of thought until the rise of modern symbolic logic.\"}, {'input_question': '8. What is the medieval outlook sometimes considered to be?', 'output_text': 'The medieval outlook is sometimes considered to be the \"Aristotelian worldview.\"'}, {'input_question': '1. What did Aristotle study?', 'output_text': 'Aristotle studied logic, metaphysics, mathematics, physics, biology, botany, ethics, politics, agriculture, medicine, dance and theatre.'}, {'input_question': \"2. Who was Aristotle's teacher?\", 'output_text': \"Aristotle's teacher was Plato.\"}, {'input_question': '4. What did Aristotle classify?', 'output_text': 'Aristotle classified areas of human knowledge into distinct disciplines such as mathematics, biology, and ethics.'}, {'input_question': '9. What does St. Thomas Aquinas refer to Aristotle as?', 'output_text': 'St. Thomas Aquinas refers to Aristotle as \"The Philosopher\" as though there were no other.'}]\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/886556137211/locations/europe-west4/pipelineJobs/tune-large-model-20231018000338\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/886556137211/locations/europe-west4/pipelineJobs/tune-large-model-20231018000338')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/europe-west4/pipelines/runs/tune-large-model-20231018000338?project=886556137211\n",
      "PipelineJob projects/886556137211/locations/europe-west4/pipelineJobs/tune-large-model-20231018000338 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/886556137211/locations/europe-west4/pipelineJobs/tune-large-model-20231018000338 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "gcs_qa_file = get_qas_from_collection(\n",
    "    project_id=PROJECT_ID,\n",
    "    collection_name=COLLECTION,\n",
    "    bucket_name=BUCKET\n",
    ")\n",
    "tuning_job = tuning(\n",
    "    project_id=PROJECT_ID,\n",
    "    gcs_qa_file=gcs_qa_file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can send a question prompt to the tuned LLM to see its answer."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
